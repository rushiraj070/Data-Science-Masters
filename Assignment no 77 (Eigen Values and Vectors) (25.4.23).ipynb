{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f655f92-0afa-42e2-b260-0df73d68810e",
   "metadata": {},
   "source": [
    "# Assignment no 77 (Eigen Values and Vectors) (25.4.23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c534aa6-3c98-442a-805e-6faa60a8ec60",
   "metadata": {},
   "source": [
    "### Q1. What are Eigen values and Eigen vectors? How are they related to the Eigen-Decomposition approach? Explain with an example.\n",
    "\n",
    "**Ans-** Eigenvalues and Eigenvectors are concepts in linear algebra that play a key role in many data analysis and machine learning algorithms. In the context of matrices, an Eigenvector of a square matrix `A` is a non-zero vector `v` such that when `A` is multiplied by `v`, the result is a scalar multiple of `v`. This scalar multiple is known as the Eigenvalue associated with the Eigenvector `v`. Mathematically, this relationship can be expressed as: `Av = λv`, where `λ` is the Eigenvalue.\n",
    "\n",
    "**Eigen-decomposition is an approach that involves decomposing a square matrix into its Eigenvectors and Eigenvalues**. Specifically, if `A` is a square matrix, then its Eigen-decomposition is given by: `A = PDP^-1`, where `P` is a matrix whose columns are the Eigenvectors of `A`, and `D` is a diagonal matrix whose entries are the corresponding Eigenvalues.\n",
    "\n",
    "As an example, consider the following 2x2 matrix:\n",
    "\n",
    "```\n",
    "A = [ 2 1 ]\n",
    "    [ 1 2 ]\n",
    "```\n",
    "\n",
    "The characteristic polynomial of this matrix is given by: `λ^2 - 4λ + 3`, which has roots at λ = 1 and λ = 3. These are the Eigenvalues of matrix `A`. The corresponding Eigenvectors can be found by solving the equation `(A - λI)v = 0` for each Eigenvalue. For λ = 1, we have:\n",
    "\n",
    "```\n",
    "[ 2 1 ]   [ 1 ]   [ 1 ]   [ 0 ]\n",
    "[ 1 2 ] - [   ] = [   ] * v = [   ]\n",
    "          [ 0 ]   [ 1 ]   [ 0 ]\n",
    "\n",
    "```\n",
    "\n",
    "Solving this system of equations gives us the Eigenvector `[1, -1]` associated with the Eigenvalue λ = 1. Similarly, for λ = 3, we have:\n",
    "\n",
    "```\n",
    "[ 2 1 ]   [ 3 ]   [ -1 ]   [ 0 ]\n",
    "[ 1 2 ] - [   ] = [    ] * v = [   ]\n",
    "          [ 0 ]   [ -1 ]   [ 0 ]\n",
    "\n",
    "```\n",
    "\n",
    "Solving this system of equations gives us the Eigenvector `[1, 1]` associated with the Eigenvalue λ = 3. Therefore, the Eigen-decomposition of matrix `A` is given by:\n",
    "\n",
    "```\n",
    "A = PDP^-1\n",
    "    where P = [ 1 -1 ]\n",
    "              [     ]\n",
    "              [ 1 -1 ]\n",
    "\n",
    "          D = [3]\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "              []\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "In summary, Eigenvalues and Eigenvectors are concepts in linear algebra that describe how a square matrix can stretch or compress vectors along certain directions. Eigen-decomposition is an approach that involves decomposing a square matrix into its Eigenvectors and Eigenvalues. This can be useful for understanding the properties of the matrix and for performing various data analysis and machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7357a28-47fe-4255-842e-1357065a7b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80d21fec-434c-487c-b9f1-c8d627584105",
   "metadata": {},
   "source": [
    "### Q2. What is eigen decomposition and what is its significance in linear algebra?\n",
    "\n",
    "**Ans-** Eigen-decomposition, also known as spectral decomposition, is a form of matrix decomposition. It involves decomposing a square matrix into a set of eigenvectors and eigenvalues. \n",
    "\n",
    "A square matrix `A` can be decomposed as `A = PDP^-1`, where:\n",
    "- `P` is a matrix whose columns are the eigenvectors of `A`.\n",
    "- `D` is a diagonal matrix whose entries are the eigenvalues of `A`.\n",
    "- `P^-1` is the inverse of the matrix `P`.\n",
    "\n",
    "The significance of eigen-decomposition in linear algebra and many other fields like data analysis, physics, and engineering is profound. Here are some key points:\n",
    "\n",
    "1. **Understanding Linear Transformations**: Eigen-decomposition helps in understanding the behavior of linear transformations represented by the matrix. The eigenvectors represent the directions in which the linear transformation only stretches or compresses the objects, and the eigenvalues represent the factor by which this stretching or compressing occurs.\n",
    "\n",
    "2. **Simplifying Complex Calculations**: Calculations involving matrices, such as raising a matrix to a power, become much simpler when expressed in terms of eigenvalues and eigenvectors.\n",
    "\n",
    "3. **Diagonalization**: If a matrix can be eigen-decomposed, then it can be diagonalized as well. This is useful because computations with diagonal matrices are much simpler than with non-diagonal matrices.\n",
    "\n",
    "4. **Data Analysis**: In data analysis and machine learning, eigen-decomposition is used in methods like Principal Component Analysis (PCA) to reduce dimensionality and to identify key variables from a large set.\n",
    "\n",
    "5. **Differential Equations**: Eigen-decomposition is also used to solve systems of differential equations.\n",
    "\n",
    "In summary, eigen-decomposition is a fundamental concept in linear algebra with wide-ranging applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0658a823-4556-4f57-8679-c6987827ffbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37a6ed80-9b39-4fe5-bd3d-ca869c2e57a0",
   "metadata": {},
   "source": [
    "### Q3. What are the conditions that must be satisfied for a square matrix to be diagonalizable using the Eigen-Decomposition approach? Provide a brief proof to support your answer.\n",
    "\n",
    "**Ans-** A square matrix is diagonalizable using the Eigen-Decomposition approach if and only if it has `n` linearly independent eigenvectors, where `n` is the size of the matrix. In other words, a matrix is diagonalizable if it has enough eigenvectors to form a complete basis for its column space.\n",
    "\n",
    "Here's a brief proof to support this statement:\n",
    "\n",
    "Let `A` be an `n x n` matrix. Suppose that `A` has `n` linearly independent eigenvectors `v1, v2, ..., vn`, with corresponding eigenvalues `λ1, λ2, ..., λn`. Let `P` be the matrix whose columns are the eigenvectors of `A`, and let `D` be the diagonal matrix whose entries are the eigenvalues of `A`. Then, by definition of eigenvectors and eigenvalues, we have:\n",
    "\n",
    "```\n",
    "AP = [Av1 Av2 ... Avn]\n",
    "   = [λ1v1 λ2v2 ... λnvn]\n",
    "   = PD\n",
    "```\n",
    "\n",
    "Since the columns of `P` are linearly independent, it follows that `P` is invertible. Multiplying both sides of the above equation by `P^-1`, we obtain:\n",
    "\n",
    "```\n",
    "APP^-1 = PDP^-1\n",
    "      => A = PDP^-1\n",
    "```\n",
    "\n",
    "Thus, if a matrix has `n` linearly independent eigenvectors, it can be diagonalized using the Eigen-Decomposition approach.\n",
    "\n",
    "Conversely, suppose that a matrix `A` can be diagonalized as `A = PDP^-1`. Then the columns of `P` are eigenvectors of `A`, and since `P` is invertible, its columns must be linearly independent. Thus, if a matrix is diagonalizable, it must have `n` linearly independent eigenvectors.\n",
    "\n",
    "In summary, a square matrix is diagonalizable using the Eigen-Decomposition approach if and only if it has enough linearly independent eigenvectors to form a complete basis for its column space. This result follows from the definition of eigenvectors and eigenvalues and the properties of invertible matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ce1c38-55d9-419a-b01a-e5e3fb61a789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "789439b2-f1d6-46bc-a372-f6f4e3465da5",
   "metadata": {},
   "source": [
    "### Q4. What is the significance of the spectral theorem in the context of the Eigen-Decomposition approach? How is it related to the diagonalizability of a matrix? Explain with an example.\n",
    "\n",
    "**Ans-** The spectral theorem is a result in linear algebra and functional analysis that provides conditions under which a linear operator or matrix can be diagonalized, i.e., represented as a diagonal matrix in some basis. This is extremely useful because computations involving a diagonalizable matrix can often be reduced to much simpler computations involving the corresponding diagonal matrix.\n",
    "\n",
    "In the context of the Eigen-Decomposition approach, the spectral theorem is significant because it identifies a class of linear operators that can be modeled by multiplication operators, which are as simple as one can hope to find. The spectral theorem also provides a canonical decomposition, called the spectral decomposition, of the underlying vector space on which the operator acts.\n",
    "\n",
    "For example, let's consider a real symmetric matrix `A`. According to the spectral theorem, `A` is orthogonally diagonalizable. This means that there exists an orthogonal matrix `P` such that `P^TAP = D`, where `D` is a diagonal matrix. The columns of `P` are the eigenvectors of `A`, and the entries of `D` are the corresponding eigenvalues. This is called the Eigen-Decomposition of `A`.\n",
    "\n",
    "In summary, the spectral theorem provides conditions under which a matrix can be diagonalized, and this is useful in the context of the Eigen-Decomposition approach because it allows us to represent a matrix as a diagonal matrix in some basis, which simplifies computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf7f419-19a6-48ca-9860-f670f4ae5c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3c77c1d-16c1-4168-bc6a-3945d3f837fb",
   "metadata": {},
   "source": [
    "### Q5. How do you find the eigenvalues of a matrix and what do they represent?\n",
    "\n",
    "**Ans-** The eigenvalues of a matrix are scalars that are associated with a linear transformation of a vector space. They represent the factor by which an eigenvector is stretched when the matrix is applied to it⁵. In other words, if `A` is a square matrix and `v` is a vector, then `λ` is a scalar quantity represented as `Av = λv`, where `λ` is considered to be the eigenvalue of matrix `A`.\n",
    "\n",
    "To find the eigenvalues of a matrix, you can follow these steps:\n",
    "1. Make sure the given matrix `A` is a square matrix. Also, determine the identity matrix `I` of the same order.\n",
    "2. Estimate the matrix `A – λI`, where `λ` is a scalar quantity.\n",
    "3. Find the determinant of matrix `A – λI` and equate it to zero.\n",
    "4. From the equation thus obtained, calculate all the possible values of `λ`, which are the required eigenvalues of matrix `A`.\n",
    "\n",
    "The computation of eigenvalues and eigenvectors for a square matrix is known as eigenvalue decomposition. The eigenvalues so obtained are usually denoted by `λ1, λ2, …..` or `e1, e2, ….`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe8475-3a80-42c0-acbf-abb16dda6116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1b4ed6f-93d0-4bcc-a8f0-1dd797e2e39d",
   "metadata": {},
   "source": [
    "### Q6. What are eigen vectors and how are they related to eigen values?\n",
    "\n",
    "**Ans-** An eigenvector is a nonzero vector that changes at most by a constant factor when a linear transformation is applied to it. The corresponding eigenvalue, often represented by `λ`, is the multiplying factor. Geometrically, a transformation matrix rotates, stretches, or shears the vectors it acts upon. The eigenvectors for a linear transformation matrix are the set of vectors that are only stretched, with no rotation or shear. The eigenvalue is the factor by which an eigenvector is stretched. If the eigenvalue is negative, the direction is reversed.\n",
    "\n",
    "In other words, if `A` is a square matrix and `v` is a vector, then `λ` is a scalar quantity represented as `Av = λv`, where `λ` is considered to be the eigenvalue of matrix `A` and `v` is the eigenvector. Eigenvectors and eigenvalues have a wide range of applications, for example in stability analysis, vibration analysis, atomic orbitals, facial recognition, and matrix diagonalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6180893b-c211-4a74-a821-1311f8345e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a92bc7bb-dd2b-4813-aab5-e916678b3478",
   "metadata": {},
   "source": [
    "### Q7. Can you explain the geometric interpretation of eigen vectors and eigen values?\n",
    "\n",
    "**Ans-** In geometric terms, an eigenvector is a vector whose direction remains unchanged when a linear transformation is applied to it. When a matrix acts upon an eigenvector, the output is a scaled version of the original vector. This scaling factor is the eigenvalue.\n",
    "\n",
    "For example, consider a transformation matrix that rotates, stretches, or shears the vectors it acts upon. The eigenvectors for this matrix are the set of vectors that are only stretched, with no rotation or shear. The eigenvalue is the factor by which an eigenvector is stretched. If the eigenvalue is negative, the direction of the eigenvector is reversed.\n",
    "\n",
    "This means that if `A` is a square matrix and `v` is an eigenvector of `A`, then `Av = λv`, where `λ` is the eigenvalue associated with `v`¹. In other words, applying the transformation `A` to the vector `v` only scales `v` by the factor `λ`, without changing its direction (unless `λ` is negative).\n",
    "\n",
    "This geometric interpretation of eigenvalues and eigenvectors provides insight into the symmetry of a given operation. For instance, in rotation matrices, the center of rotation (often origin), or axis of rotation for higher dimensional cases, are examples of vectors not changed by the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47167a2f-19d4-4d63-8feb-c1221ad5dd12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "484dcad0-e31b-447c-80db-4349e7de4b62",
   "metadata": {},
   "source": [
    "### Q8. What are some real-world applications of eigen decomposition?\n",
    "\n",
    "**Ans-** Eigen decomposition has many real-world applications. Here are some examples:\n",
    "\n",
    "- **Image compression**: Singular value decomposition, which is closely related to eigen decomposition, can be used to compress images by throwing away small eigenvalues.\n",
    "\n",
    "- **Deriving Special Relativity**: The language of linear algebra, including eigenvalues and eigenvectors, can be used to derive Special Relativity. In fact, Einstein's second postulate states that \"Light is an eigenvector of the Lorentz transform\".\n",
    "\n",
    "- **Spectral Clustering**: Eigen decomposition can be used in spectral clustering, which is a technique used to partition a dataset into clusters based on the similarity between data points.\n",
    "\n",
    "- **System of first-order differential equations**: Eigenvalues and eigenvectors can be used to solve systems of first-order differential equations.\n",
    "\n",
    "- **Google's PageRank algorithm**: The well-known PageRank algorithm, used by Google to rank web pages in their search engine results, is based on the concept of eigenvectors.\n",
    "\n",
    "These are just a few examples of the many real-world applications of eigen decomposition. It is a powerful tool with a wide range of uses in various fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a6bfd-7240-4e66-8bcf-581c96637e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9988b26-ab5e-4f4e-a941-012c3eb673db",
   "metadata": {},
   "source": [
    "### Q9. Can a matrix have more than one set of eigen vectors and eigen values?\n",
    "\n",
    "**Ans-** Yes, a matrix can have more than one set of eigenvectors and eigenvalues. Matrices can have more than one eigenvector sharing the same eigenvalue. The converse statement, that an eigenvector can have more than one eigenvalue, is not true, which you can see from the definition of an eigenvector. However, there's nothing in the definition that stops us from having multiple eigenvectors with the same eigenvalue.\n",
    "\n",
    "If a matrix has more than one eigenvector, the associated eigenvalues can be different for the different eigenvectors. Geometrically, the action of a matrix on one of its eigenvectors causes the vector to stretch (or shrink) and/or reverse direction.\n",
    "\n",
    "If the eigenvalues are distinct, then there is only one set of unit size eigenvectors. If there are duplicate eigenvalues, then for these eigenvalues, the eigenvectors are not distinct (but any eigenvectors corresponding to unique eigenvalues are still distinct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4035d7-c75a-4e18-b2bc-f5c3e6d5d486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "840729da-3d6c-4171-a20e-cccdd50d7fee",
   "metadata": {},
   "source": [
    "### Q10. In what ways is the Eigen-Decomposition approach useful in data analysis and machine learning? Discuss at least three specific applications or techniques that rely on Eigen-Decomposition.\n",
    "\n",
    "**Ans-** Eigen-Decomposition is a powerful tool in data analysis and machine learning. Here are three specific applications or techniques that rely on Eigen-Decomposition:\n",
    "\n",
    "1. **Principal Component Analysis (PCA)**: PCA is a technique used to reduce the dimensionality of data by transforming the correlated features in the data into linearly independent (orthogonal) components. This is done by decomposing the covariance matrix of the data into its eigenvectors and eigenvalues, and then projecting the data onto the eigenvectors. The eigenvectors with the largest eigenvalues capture most of the variance in the data, and can be used to represent the data in a lower-dimensional space.\n",
    "\n",
    "2. **Spectral Clustering**: Spectral clustering is a technique used to partition a dataset into clusters based on the similarity between data points. This is done by constructing a similarity matrix for the data, and then decomposing this matrix into its eigenvectors and eigenvalues. The eigenvectors corresponding to the smallest eigenvalues are then used to represent the data in a lower-dimensional space, where traditional clustering algorithms can be applied.\n",
    "\n",
    "3. **Latent Semantic Analysis (LSA)**: LSA is a technique used to analyze relationships between a set of documents and the terms they contain. This is done by constructing a term-document matrix for the data, and then decomposing this matrix into its eigenvectors and eigenvalues. The eigenvectors with the largest eigenvalues capture most of the variance in the data, and can be used to represent the documents in a lower-dimensional space, where similarities between documents can be computed.\n",
    "\n",
    "These are just a few examples of how Eigen-Decomposition is used in data analysis and machine learning. It is a powerful tool with many applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55896178-5ec4-4aa3-84ea-542109177130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
