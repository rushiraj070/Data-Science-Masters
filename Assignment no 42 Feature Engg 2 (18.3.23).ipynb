{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5277a1cf-8889-4cb4-85d0-1f70832616c6",
   "metadata": {},
   "source": [
    "## Assignment no 42 Feature Engg 2 (18.3.23)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47dd6fbd-ce82-4c21-af85-3afc616654ac",
   "metadata": {},
   "source": [
    "# Submitted on 25.4.2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609baef2-d5b3-4ebb-8cb4-d77c44c73469",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is the Filter method in feature selection, and how does it work?\n",
    "\n",
    "Ans- The Filter method in feature selection involves evaluating the relevance of each feature independently of the \n",
    "    predictive model. It ranks features based on certain criteria, such as statistical measures like correlation with \n",
    "    the target variable, mutual information, or significance tests. Features are then selected or eliminated based on \n",
    "    these rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ebf61a-1c94-4f47-b0d1-c2a7c60eef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. How does the Wrapper method differ from the Filter method in feature selection?\n",
    "\n",
    "Ans- The Wrapper method differs from the Filter method in that it evaluates subsets of features by training and testing \n",
    "    the model with different combinations of features. It uses a specific machine learning algorithm to score feature\n",
    "    subsets, typically through techniques like forward selection, backward elimination, or recursive feature elimination."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f72c5df7-8b27-47e2-bae9-b4dd7aa2aa36",
   "metadata": {},
   "source": [
    "### Theoretical Example:\n",
    "\n",
    "Suppose you have a dataset with the following features: Age, Income, Education, and Location. You want to predict whether a person will buy a particular product based on these features. Using the Wrapper method, you would perform feature selection by iteratively evaluating subsets of features and selecting the subset that yields the best model performance.\n",
    "\n",
    "1. **Forward Selection:**\n",
    "   - Start with an empty set of features.\n",
    "   - Iteratively add one feature at a time, training the model and evaluating its performance.\n",
    "   - Select the subset of features that maximizes model performance according to a chosen evaluation metric (e.g., accuracy, precision, recall).\n",
    "\n",
    "2. **Backward Elimination:**\n",
    "   - Start with all features included.\n",
    "   - Iteratively remove one feature at a time, training the model and evaluating its performance.\n",
    "   - Select the subset of features that maximizes model performance according to the chosen evaluation metric.\n",
    "\n",
    "3. **Recursive Feature Elimination:**\n",
    "   - Train the model with all features.\n",
    "   - Rank features based on their importance or coefficients.\n",
    "   - Remove the least important feature(s) iteratively until the desired number of features is reached.\n",
    "\n",
    "### Code Example (Using Python and scikit-learn):\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize Recursive Feature Elimination (RFE) with the random forest classifier\n",
    "rfe = RFE(estimator=clf, n_features_to_select=2, step=1)\n",
    "\n",
    "# Fit RFE to training data\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Print selected features\n",
    "selected_features = [i for i, val in enumerate(rfe.support_) if val]\n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# Evaluate model performance on test data\n",
    "accuracy = rfe.score(X_test, y_test)\n",
    "print(\"Accuracy with selected features:\", accuracy)\n",
    "```\n",
    "\n",
    "In this code example:\n",
    "- We load the Iris dataset and split it into training and testing sets.\n",
    "- We initialize a random forest classifier and then use RFE (Recursive Feature Elimination) with the random forest classifier as the estimator.\n",
    "- We fit RFE to the training data, specifying the number of features to select (in this case, 2).\n",
    "- After fitting, we print the selected features and evaluate the model's accuracy on the test data using only the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa3624-b8cc-4b92-b0b2-ef08da6f03df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What are some common techniques used in Embedded feature selection methods?\n",
    "\n",
    "Ans- Embedded feature selection methods integrate feature selection into the model training process itself. Common \n",
    "    techniques include Lasso (L1 regularization), Ridge (L2 regularization), Elastic Net, decision trees with feature \n",
    "    importance measures, and gradient boosting machines with built-in feature selection capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7caefc-71ea-4799-a535-7e08b6686edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. What are some drawbacks of using the Filter method for feature selection?\n",
    "\n",
    "Ans- Drawbacks of using the Filter method for feature selection include its inability to consider feature interactions, \n",
    "    its potential to discard redundant features rather than selecting the most informative ones, and its reliance on \n",
    "    predetermined metrics that may not fully capture the relationship between features and the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ae9ce-db97-4228-8643-63ea94fba16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature selection?\n",
    "\n",
    "Ans- The Filter method may be preferred over the Wrapper method when dealing with high-dimensional datasets, as it tends \n",
    "    to be computationally less expensive. Additionally, the Filter method can provide a quick overview of feature relevance\n",
    "    without requiring extensive model training, making it suitable for exploratory data analysis or as a preprocessing \n",
    "    step before applying more computationally intensive methods like the Wrapper method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d45189c-7724-45c0-ad9b-314f5af67728",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6. In a telecom company, you are working on a project to develop a predictive model for  customer churn. You are unsure \n",
    "    of which features to include in the model because the dataset contains several different ones. Describe how you would \n",
    "    choose the most pertinent attributes for the model using the Filter Method.\n",
    "\n",
    "Ans- To choose the most pertinent attributes for the customer churn predictive model using the Filter method:\n",
    "    1. Calculate relevant statistical measures such as correlation coefficients between each feature and the target \n",
    "       variable (churn).\n",
    "    2. Perform significance tests to identify features significantly associated with churn.\n",
    "    3. Apply techniques like mutual information to assess the information gain of each feature regarding churn.\n",
    "    4. Select the top-ranked features based on these criteria for inclusion in the predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86b0b9-1b03-44fd-8068-4041fc5bad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7. You are working on a project to predict the outcome of a soccer match. You have a large dataset with many features, \n",
    "    including player statistics and team rankings. Explain how you would use the Embedded method to select the most \n",
    "    relevant features for the model.\n",
    "\n",
    "Ans- To select the most relevant features for predicting soccer match outcomes using the Embedded method:\n",
    "    1. Utilize techniques like decision trees or gradient boosting machines with feature importance measures.\n",
    "    2. Train the model on the entire dataset, allowing the algorithm to automatically select the most informative features \n",
    "       during the training process.\n",
    "    3. Evaluate the importance scores assigned to each feature by the model and select the top-ranked features for\n",
    "       prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e3e597-7e04-41b4-86ca-9303abcf66e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8. You are working on a project to predict the price of a house based on its features, such as size, location, and age. \n",
    "    You have a limited number of features, and you want to ensure that you select the most important ones for the model. \n",
    "    Explain how you would use the Wrapper method to select the best set of features for the predictor.\n",
    "\n",
    "Ans- To select the best set of features for predicting house prices using the Wrapper method:\n",
    "    1. Employ techniques like forward selection, backward elimination, or recursive feature elimination with a chosen \n",
    "       machine learning algorithm (e.g., linear regression).\n",
    "    2. Start with an initial set of features and iteratively add or remove features based on their impact on model \n",
    "       performance.\n",
    "    3. Evaluate the performance of the model with each subset of features using cross-validation or a separate validation \n",
    "       dataset.\n",
    "    4. Select the subset of features that results in the best model performance as determined by metrics such as mean \n",
    "       squared error or R-squared."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
