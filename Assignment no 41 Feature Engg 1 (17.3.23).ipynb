{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5277a1cf-8889-4cb4-85d0-1f70832616c6",
   "metadata": {},
   "source": [
    "## Assignment no 41 Feature Engg 1 (17.3.23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8efd5cb-eca8-4bd1-8273-77cbb1841420",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some \n",
    "algorithms that are not affected by missing values.\n",
    "\n",
    "Ans - Missing data, or missing values, occur when you dont have data stored for certain variables or participants. Data can \n",
    "    go missing due to incomplete data entry, equipment malfunctions, lost files, and many other reasons. In any dataset, \n",
    "    there are usually some missing data.\n",
    "    \n",
    "    Missing data are typically grouped into three categories:\n",
    "        1. MCAR (Missing Completely At Random) - Missing data/values is/are unrelated to both the observed data and the \n",
    "                                                 missing data.\n",
    "            \n",
    "        2. Missing at Random (MAR) - Missing data/values depends only on the observed data, but not on the missing data itself.\n",
    "        \n",
    "        3. Missing Not at Random (MNAR) - Probability of missing values depends on the value of the missing data itself.\n",
    "        \n",
    "    One of the biggest impact of Missing Data is, It can bias the results of the machine learning models or reduce the accuracy\n",
    "    of the model. So, It is very important to handle missing values.\n",
    "    \n",
    "    Following are the Machine learning algorithms that don’t require handling the missing values explicitly:\n",
    "        1. Histogram based Gradient-boosting Classifier / Regressor\n",
    "        2. k-NN algorithm\n",
    "        3. Random Forest algorithms\n",
    "        4. Decision Trees\n",
    "        5. Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa3624-b8cc-4b92-b0b2-ef08da6f03df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2: List down techniques used to handle missing data.  Give an example of each with python code.\n",
    "\n",
    "Ans - Techniques for Handling Missing Data are as follows - \n",
    "        1. Deleting entire Row/Column\n",
    "            e.g df.dropna(axis = 1) # for dropping entire column which contains null values\n",
    "                df.dropna(axis = 0) # for dropping entire row which contains null values\n",
    "            \n",
    "        2. Replacing missing values with mean value within variable. (for numerical values)\n",
    "             e.g  step 1 - Finding the mean of particular column which contains missing values by mean() method.\n",
    "                            df[\"column_name\"].mean()\n",
    "                  step 2 - Filling cells of missing values by fillna() method.\n",
    "                            df[\"column_name\"].fillna(df[\"column_name\"].mean())\n",
    "                    \n",
    "        3. Replacing missing values with median value within variable. (for numerical values)\n",
    "            e.g  step 1 - Finding the median of particular column which contains missing values by median() method.\n",
    "                            df[\"column_name\"].median()\n",
    "                 step 2 - Filling cells of missing values by fillna() method.\n",
    "                            df[\"column_name\"].fillna(df[\"column_name\"].median())\n",
    "                    \n",
    "        4. Replacing missing values with mode value within variable. (for categorical values)\n",
    "            e.g  step 1 - Finding the mode value of particular column from non null cells which contains missing values by \n",
    "                          mode() method.\n",
    "                            df[df[\"column_name\"].notna()].mode()\n",
    "                 step 2 - Filling cells of missing cells by fillna() method.\n",
    "                            df[\"column_name\"].fillna(df[df[\"column_name\"].notna()].mode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7caefc-71ea-4799-a535-7e08b6686edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?\n",
    "\n",
    "Ans -  When in dataset a particular category or column contains more number of categorical value than the other then the data\n",
    "    is said to be Imbalanced Data and can be divided as major and minor.\n",
    "    If we not the imbalanced data properly, when we built our Machine Learning model, it will bias towards major data.\n",
    "    In other words our model cant be trained properly as well as predict the correct or True outcome when we input or feed \n",
    "    the foreign data to it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ae9ce-db97-4228-8643-63ea94fba16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-sampling are required.\n",
    "\n",
    "Ans - Up-sampling and Down-sampling are the effective ways or techniques to handle imbalanced data with respect the majority\n",
    "    class.\n",
    "\n",
    "Down-sampling means reducing the datapoints of majority class and level it to minority but the main drawback of \n",
    "    this technique is we have bear the data loss in huge amount so used only when the prediction is not that important and\n",
    "    used to get only and clear idea an not an conclusion.\n",
    "    \n",
    "Up-sampling means increaing the datapoints of minority class and levelup to majority most of the times this technique is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d45189c-7724-45c0-ad9b-314f5af67728",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5: What is data Augmentation? Explain SMOTE.\n",
    "\n",
    "Ans- Data augmentation is a set of techniques to artificially increase the amount of data by generating new data points from\n",
    "    existing data.\n",
    "    \n",
    "        Synthetic Minority Over-sampling Technique also known as SMOTE was introduced by Nitesh V. Chawla which is an \n",
    "    over-sampling technique focused on generating synthetic tabular data. The general idea of SMOTE is the \n",
    "    generation of synthetic data between each sample of the minority class and its “k” nearest neighbors. That is, for each \n",
    "    one of the samples of the minority class, its “k” nearest neighbors are located (by default k = 5), then between the pairs \n",
    "    of points generated by the sample and each of its neighbors, a new synthetic data is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86b0b9-1b03-44fd-8068-4041fc5bad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n",
    "\n",
    "Ans - An outlier is an observation that lies an abnormal distance from other values in a random sample from a population.\n",
    "    Outliers are extreme values that stand out greatly from the overall pattern of values in a dataset or graph.\n",
    "    \n",
    "\n",
    "    Outliers increase the variability in your data, which decreases statistical power. Consequently, excluding outliers \n",
    "can cause your results to become statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e3e597-7e04-41b4-86ca-9303abcf66e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7: You are working on a project that requires analyzing customer data. However, you notice that some of \n",
    "the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
    "\n",
    "Ans - If the column contains missing values also which is not important and will not be used or included as a part of \n",
    "    training dataset the I will delete that entire column.\n",
    "    \n",
    "     If the column contains missing values which are numerical or continuous and will  be used or included as a part of \n",
    "    training dataset the I will first find mean or median depending on condition and replace it that particular mean or \n",
    "    median value.\n",
    "    \n",
    "     If the column contains missing values which are categorical and will  be used or included as a part of \n",
    "    training dataset the I will first find mode depending on condition and replace it that particular mode value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75009a4-f96d-4a4f-babe-ae0f8a97edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are \n",
    "some strategies you can use to determine if the missing data is missing at random or if there is a pattern \n",
    "to the missing data?\n",
    "\n",
    "Ans - \n",
    "    There are several strategies that can be used to determine if the missing data is missing at random or if there is a \n",
    "    pattern to the missing data:\n",
    "\n",
    "    1. Visualization: One strategy is to visualize the data using plots and graphs to see if there are any patterns or trends\n",
    "            in the missing data. For example, a heatmap can be used to show which values are missing in the dataset.\n",
    "\n",
    "    2. Summary statistics: Another strategy is to calculate summary statistics for the missing data and compare them to the \n",
    "            summary statistics for the non-missing data. If there are significant differences between the two, this may \n",
    "            suggest that the missing data is not missing at random.\n",
    "\n",
    "    3. Imputation: Imputation can also be used to determine if the missing data is missing at random. If the imputed values \n",
    "            are similar to the non-missing values, this may suggest that the missing data is missing at random. If the imputed\n",
    "            values are significantly different, this may suggest that there is a pattern to the missing data.\n",
    "\n",
    "    4. Statistical tests: Statistical tests can also be used to determine if the missing data is missing at random. \n",
    "            For example, a chi-square test can be used to test whether the missing data is independent of other variables in \n",
    "            the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d04bfb-6f60-459b-9c84-5a3d9a1638ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the \n",
    "dataset do not have the condition of interest, while a small percentage do. What are some strategies you \n",
    "can use to evaluate the performance of your machine learning model on this imbalanced dataset?\n",
    "\n",
    "Answer: There are various reasons for having no interest in medical diagnosis or process of treatment for any health related\n",
    "    issues such as no self consciousness about health, negative thoughts or fear about treatment/s ,cost of medications,\n",
    "    mistrust, lack of symptoms, worry, thinking o self reilability etc.\n",
    "     Within digital world we can use following strategies respect available dataset to evaluate the performance:\n",
    "            \n",
    "1. Confusion Matrix: A confusion matrix is a table that summarizes the performance of a classifier on a dataset. It displays\n",
    "            the number of true positives, false positives, true negatives, and false negatives. A confusion matrix can help \n",
    "            to evaluate the performance of the model, especially when dealing with imbalanced datasets.\n",
    "\n",
    "2. Precision, Recall, and F1-score: Precision, recall, and F1-score are metrics that are commonly used to evaluate the \n",
    "            performance of machine learning models on imbalanced datasets. Precision is the fraction of true positive \n",
    "            predictions among all positive predictions, while recall is the fraction of true positive predictions among \n",
    "            all actual positive instances. F1-score is the harmonic mean of precision and recall. \n",
    "                These metrics are useful when evaluating the performance of models on imbalanced datasets because they take\n",
    "            into account both the false positive and false negative rates.\n",
    "\n",
    "3. ROC Curve and AUC: ROC (Receiver Operating Characteristic) curve is a plot of the true positive rate against the false \n",
    "            positive rate. AUC (Area Under the ROC Curve) is a metric that measures the area under the ROC curve. \n",
    "            ROC curve and AUC can be used to evaluate the performance of a model on an imbalanced dataset. \n",
    "            A high AUC value suggests that the model is performing well on the dataset.\n",
    "\n",
    "4. Resampling techniques: Resampling techniques such as oversampling the minority class or undersampling the majority class \n",
    "            can also be used to balance the dataset. Once the dataset is balanced, standard metrics such as accuracy, \n",
    "            precision, recall, F1-score, and ROC can be used to evaluate the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499f6d3-9e26-425b-8e35-cd43be65e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is \n",
    "unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to \n",
    "balance the dataset and down-sample the majority class?\n",
    "\n",
    "Ans - \n",
    "1. Random undersampling: This method involves randomly selecting a subset of observations from the majority class to match \n",
    "        the size of the minority class. This can be done using techniques such as RandomUnderSampler from the imblearn \n",
    "        library in Python.\n",
    "\n",
    "2. Tomek links: This method involves identifying pairs of observations that are nearest neighbors and belong to different \n",
    "        classes. The observation from the majority class is then removed to balance the dataset. This can be done using \n",
    "        techniques such as TomekLinks from the imblearn library in Python.\n",
    "\n",
    "3. Synthetic minority oversampling technique (SMOTE): This method involves generating synthetic observations for the \n",
    "        minority class to match the size of the majority class. SMOTE can be used in combination with random undersampling \n",
    "        to balance the dataset. This can be done using techniques such as SMOTETomek from the imblearn library in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2cd295-86e0-4f01-81ed-b9bc84ba0d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a \n",
    "project that requires you to estimate the occurrence of a rare event. What methods can you employ to \n",
    "balance the dataset and up-sample the minority class?\n",
    "\n",
    "Ans - \n",
    "1. Random oversampling: This method involves randomly duplicating observations from the minority class to match the size of \n",
    "        the majority class. This can be done using techniques such as RandomOverSampler from the imblearn library in Python.\n",
    "\n",
    "2. Synthetic minority oversampling technique (SMOTE): This method involves generating synthetic observations for the minority\n",
    "        class to match the size of the majority class. SMOTE can be used in combination with random oversampling to balance \n",
    "        the dataset. This can be done using techniques such as SMOTE from the imblearn library in Python.\n",
    "\n",
    "3. Adaptive synthetic sampling (ADASYN): This method is similar to SMOTE but focuses on generating more synthetic observations\n",
    "        for the minority class samples that are harder to learn. This can be done using techniques such as ADASYN from the \n",
    "        imblearn library in Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
