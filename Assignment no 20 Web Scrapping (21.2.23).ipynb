{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cca7695-b4af-43b5-a357-173940a3a0a6",
   "metadata": {},
   "source": [
    "# Assignment on Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8441e91-59a8-4c5e-a9ad-442f161b86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "Ans - Web scraping (or data scraping) is a technique used to collect content and data from the internet. This data is usually\n",
    "    saved in a local file so that it can be manipulated and analyzed as needed. If you’ve ever copied and pasted content from\n",
    "    a website into an Excel spreadsheet, this is essentially what web scraping is, but on a very small scale.\n",
    "    \n",
    "    Web scraping has countless applications, especially within the field of data analytics. Market research companies use \n",
    "    scrapers to pull data from social media or online forums for things like customer sentiment analysis, Others scrape data to\n",
    "    support competitor analysis (e.g. Amazon, Flipkart, eBay ),some uses web scraping to analyze, rank, and index their \n",
    "    content (e.g. Google), Many companies also carry out contact scraping, which is when they scrape the web for contact \n",
    "    information to be used for marketing purposes.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fed609-d5bc-41cd-b500-8460b58afaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "Ans - MANUAL SCRAPING e.g. COPY-PASTING\n",
    "\n",
    "    AUTOMATED SCRAPING\n",
    "    \n",
    "    1 . HTML PARSING - HTML parsing is done with JavaScript and targets linear or nested HTML pages. It is a fast and robust\n",
    "                       method that is used for text extraction, screen scraping, and resource extraction among others.\n",
    "\n",
    "    2. DOM PARSING - DOM is short for Document Object Model and it defines the style structure and content of XML files. \n",
    "                    Scrapers make use of DOM parsers to get an in-depth view of a web page’s structure. They can also use a \n",
    "                    DOM parser to get nodes containing information and then use a tool like XPath to scrape web pages. \n",
    "                    Internet Explorer or Firefox browsers can be embedded to extract the entire web page or just parts of it.\n",
    "\n",
    "    3. VERTICAL AGGREGATION - Vertical aggregation platforms are created by companies with access to large scale computing power \n",
    "                              to target specific verticals. Some companies run the platforms on the cloud. Bots creation and\n",
    "                              monitoring for specific verticals are done by these platforms without any human intervention. \n",
    "                              The quality of the bots is measured based on the quality of data they extract since they are created based on the knowledge base for the specific vertical.\n",
    "                \n",
    "\n",
    "    4. XPATH - XML Path Language is a query language that is used with XML documents. XPath can be used to navigate XML documents \n",
    "               because of their tree-like structure by selecting nodes based on different parameters. XPath can be used together\n",
    "               with DOM parsing to scrape an entire web page.\n",
    "\n",
    "    5 .GOOGLE SHEETS - Google sheets are a web scraping tool that is quite popular among web scrapers. From within sheets, \n",
    "                    a scraper can make use of IMPORT XML (,) function to scrape as much data as is needed from websites. This \n",
    "                    method is only useful when specific data or patterns are required from a website. You can also use this \n",
    "                    command to check if your website is secure from scraping.\n",
    "\n",
    "    6. TEXT PATTERN MATCHING\n",
    "                This is a matching technique that involves the use of the UNIX grep command and is used with popular programming languages like Perl or Python.\n",
    "\n",
    "                Web scraping technique involves the use of tools and services that can be easily gotten online. In order to be proficient in web scraping, you need to know all the techniques, or you can give the task to a freelancer to do it for you. Automated web scraping tools and services include limeproxies, cURL, Wget, HTTrack, Import.io, Node.js, and a list of others. For scraping purposes, scrapers usually make use of headless browsers like Phantom.js, Slimmer.js, and Casper.js.\n",
    "\n",
    "Other web scraping technologies to master are:\n",
    "\n",
    "1 . SELENIUM\n",
    "            Selenium is a web browser automation tool that allows you to do a lot of preset things as with the use of a bot. \n",
    "            learning to use Selenium will go a long way in helping you find out how websites work. Using it can mimic a normal \n",
    "            human visit to a page using a regular web browser and this will allow you to get accurate data. Often times, it is \n",
    "            used in emulating ajax calls in web scraping too.\n",
    "\n",
    "            Being a powerful automation tool, it can give you more than just the capacity to perform web scraping. You can also \n",
    "            test websites and automate any time-consuming action on the web.\n",
    "\n",
    "2. BOILERPIPE\n",
    "            When you have to extract text together with the associated titles, Boilerpipe will come in handy. Boilerpipe is a \n",
    "            java library that is made for data extraction from the web be it structured or unstructured data. It takes care of \n",
    "            the unwanted HTML tags and other noise found in web pages leaving you with clean text. An endearing feature of this \n",
    "            technology is that it does web scraping rapidly with little input from the user. The speed does not affect the accuracy \n",
    "            of data as it has high accuracy and all these make it one of the easiest scraping tools available.\n",
    "\n",
    "3. NUTCH\n",
    "        When the topic of a gold standard web scraping technology is mentioned, Nutch is one of the top options that will be \n",
    "        presented. It is an open-source web crawler that extracts data from web pages at lightning speed. Nutch crawls, extracts \n",
    "        and stores data once it has been programmed. Its powerful algorithm is what makes it stand out as one of the best web \n",
    "        scraping tools available.\n",
    "\n",
    "In order to scrap with Nutch, the web pages have to be coded into Nutch manually. Once this has been done it will scan \n",
    "through the pages and fetch the required data and store it in the server.\n",
    "\n",
    "4 . WATIR\n",
    "        Watir (which is pronounced as water) is an open-source Ruby library family that is a good choice for web browser automation \n",
    "        as it is easy to use and is very flexible. One of the reasons why it is perfect for use in web scraping is because it \n",
    "        interacts with web browsers the same way humans do.\n",
    "\n",
    "        It can be used to click links, filling forms, pressing buttons, and anything you can imagine a human doing on a web page. \n",
    "        Ruby makes the use of Watir very enjoyable and easy as Ruby just like other programming languages gives you the ability to \n",
    "        read data files, export XML, connect to databases, and write spreadsheets.\n",
    "\n",
    "5 .CELERITY\n",
    "        This is a JRuby wrapper created around HtmlUnit (a headless java browser with support for JavaScript). Its API is easy to\n",
    "        use and allows you to navigate easily through web applications. It runs at a very impressive speed as there are no \n",
    "        time-consuming GUI rendering or unnecessary downloads involved. Since it is scalable and non-intrusive, it can run in the \n",
    "        background silently after it has been set up initially. Celerity is a good browser automation tool that you can use for \n",
    "        effective web scraping.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2d11d9-2edb-4cbf-b648-5da84ec82984",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "Ans - \n",
    "        Beautiful Soup is a Python library designed for quick turnaround projects like screen-scraping. \n",
    "        Three features make it powerful:\n",
    "            1. Beautiful Soup provides a few simple methods and Pythonic idioms for navigating, searching, and modifying a \n",
    "                parse tree: a toolkit for dissecting a document and extracting what you need. It doesn't take much code to write \n",
    "                an application.\n",
    "                \n",
    "            2. Beautiful Soup automatically converts incoming documents to Unicode and outgoing documents to UTF-8. You \n",
    "                don't have to think about encodings, unless the document doesn't specify an encoding and Beautiful Soup \n",
    "                can't detect one. Then you just have to specify the original encoding.\n",
    "                \n",
    "            3. Beautiful Soup sits on top of popular Python parsers like lxml and html5lib, allowing you to try out \n",
    "                different parsing strategies or trade speed for flexibility.\n",
    "                \n",
    "            4. Beautiful Soup parses anything you give it, and does the tree traversal stuff for you. You can \n",
    "                tell it \"Find all the links\", or \"Find all the links of class externalLink\", or \"Find all the links \n",
    "                whose urls match \"foo.com\", or \"Find the table heading that's got bold text, then give me that text.\"\n",
    "\n",
    "Valuable data that was once locked up in poorly-designed websites is now within your reach. Projects that would have taken \n",
    "hours take only minutes with Beautiful Soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475cdb6e-3cd9-438d-8b71-78a48fbc163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Why is flask used in this Web Scraping project?\n",
    "\n",
    "Ans - Flask is a lightweight framework to build websites. We'll use this to parse our collected data and display it as \n",
    "    HTML in a new HTML file. The requests module allows us to send http requests to the website we want to scrape. \n",
    "    The first line imports the Flask class and the render_template method from the flask library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a22d6b-a89a-4729-9d01-73625db371af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "Ans - Code Pipeline and Beanstalk are the services used in our project conducted in session.\n",
    "        \n",
    "        Code Pieline -\n",
    "            AWS CodePipeline is a fully managed continuous delivery service that helps you automate your release pipelines \n",
    "            for fast and reliable application and infrastructure updates.\n",
    "            \n",
    "        Beanstalk -\n",
    "            AWS Elastic Beanstalk automates the details of capacity provisioning, load balancing, auto scaling, and \n",
    "            application deployment, creating an environment that runs a version of your application. You can simply \n",
    "            upload your deployable code (e.g., WAR file, PY file), and AWS Elastic Beanstalk does the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2778d47-949e-44a8-b522-4056235fcd80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
